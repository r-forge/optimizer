---
title: "Optimization Objects"
author: "Duncan Murdoch"
output:
  rmarkdown::html_vignette:
    toc: yes
---

# Introduction

These are notes describing a proposal for "optimization objects", a format
to unify the inputs and outputs from optimization functions.

Currently base R has many different optimizers (`optim()`, `nls()`, `nlm()`, etc.)
each with different strengths, but also each with different requirements for 
inputs.  The `optimx` and `optimz` packages are an attempt to unify these
(and others) into a common interface, to make comparison of the results easier.
This proposal carries that unification further.

# General Idea

The `optimx()` function should accept as input an optimization object.  The
object should contain sufficient information about the optimization problem
to allow choice of an optimizer and construction of defaults for all necessary 
arguments for that optimizer.

The result should also be an optimization object.  In addition to the inputs, 
the result should contain information about the outcome of the optimization 
attempt, and perhaps a history of previous attempts.  (There needs to be 
some control over the level of detail here, but it should at least be possible
to contain full trace information from previous attempts.)

# Details

I am thinking about this as if the objects are implemented in S3, but
this proposal is preliminary, so all of the suggestions are tentative,
including the form of the objects.

Fields in the object:

* `par`:  A vector of named parameter values, used to initialize the optimizer.
* `fn`:   A function with signature `f(par, ...)`: the objective function
* `methods`:  A vector of names of optimization methods to try.

Optional fields:

* `gr`:   An optional field to compute the gradient.
* `lower`, `upper`:  Bounds on the allowable range of the parameters.
* `results`:  A list of results of previous attempts.
* `transform`: A transformation to the arguments. This
converts the `par` vector to a more convenient form, or inverts that transformation,
functions that evaluate the objective or gradient in the more convenient
form, etc.  The underlying optimizer will only see the convenient form, but 
the results that are returned will be translated back to the user specified form.
Examples would include fixing some parameters for profiling, 
forcing several parameters to be
functions of a single underlying one (e.g. optimizing `f(x=s, y=s)` over `s`),
or partially linear models, or functions to plot the
current state every `n` evaluations.

# Prototype

This is the kind of thing I am thinking of.  This only supports `optim`; the
real thing needs to be much more elaborate.

```{r}
optimization <- function(par, fn, gr = NULL, ...,
      methods = knownMethods,
      lower = -Inf, upper = Inf,
      control = list(), hessian = FALSE, transform = NULL) {
    knownMethods <- c("Nelder-Mead", "BFGS", "CG", "L-BFGS-B", "SANN",
                 "Brent") 
    if (!is.null(transform)) 
      transform$setfn(fn, gr)
    result <- list(par = par, fn = fn, gr = gr, 
    	           dots = list(...), lower = lower, upper = upper,
    	           control = control, hessian = hessian, 
    	           transform = transform)
    if (!missing(methods))
      result$methods <- match.arg(methods, knownMethods, several.ok = TRUE)
    else
      result$methods <- knownMethods[1]
    structure(result, class = "optimization")
}

print.optimization <- function(x, ...) {
  cat("Optimization object.")
  if (!is.null(x$value)) {
    cat("  fn(", paste(format(x$par), collapse=","), ") = ", 
                 format(x$value),"\n", sep="")
  } else
    cat("  Not run yet.\n")
}

run.optimization <- function (x, verbose = TRUE) {
  if (is.null(x$runs))
    x$runs <- list()
  if (is.null(x$value))
    x$value <- do.call(x$fn, c(list(x$par), x$dots))
  for (method in x$methods) {
    args <- unclass(x)
    args$method <- method
    args$methods <- NULL
    args$runs <- NULL
    args$value <- NULL
    args$dots <- NULL
    args$transform <- NULL
    if (is.list(args$lower)) {
    	args$lower <- args$lower[[method]]
        if (is.null(args$lower)) 
          args$lower <- -Inf
    }
    if (is.list(args$upper)) {
    	args$upper <- args$upper[[method]]
    	if (is.null(args$upper))
    	  args$upper <- Inf
    }
    if (is.list(args$control) && all(names(args$control) %in% x$methods)) {
    	args$control <- args$control[[method]]
    	if (is.null(args$control))
    	  args$control <- list()
    }
    if (is.list(args$hessian)) {
    	args$hessian <- args$hessian[[method]]
    	if (is.null(args$hessian))
    	  args$hessian <- FALSE
    }
    if (!is.null(x$transform)) {
    	args$par <- x$transform$forward(args$par)
    	args$lower <- x$transform$forward(rep(args$lower, length=length(x$par)))
    	args$upper <- x$transform$forward(rep(args$upper, length=length(x$par)))
    	args$fn <- x$transform$fn1
    	if (!is.null(x$gr)) 
    	  args$gr <- x$transform$gr1
    }
    if (verbose)
        cat("Trying method = '", method, "'\n", sep = "")
    run <- do.call("optim", c(args, x$dots))
    x$runs <- c(x$runs, list(run))
    if (run$value < x$value) {
    	x$value <- run$value
    	x$par <- run$par
    	if (!is.null(x$transform))
    	  x$par <- x$transform$inverse(x$par)
    	if (verbose) {
    	  cat("  ")
    	  print(x)
    	}
    } else 
    	if (verbose)
    	  cat("  No improvement.\n")
  }
  if (verbose) invisible(x)
  else x
}
```

Here we try it to optimize the function $(x-1)^2 + (x-y-3)^4 + 0.0001*(y-4)^4 + 1$.  I use methods SANN followed by Nelder-Mead with a limit of 20 iterations,
just so that the problem doesn't get optimized in the very first try.
```{r}
fn <- function(arg) {
  x <- arg[1]
  y <- arg[2]
  (x-1)^2 + (x-y-3)^4 + 0.0001*(y-4)^4 + 1
}
opt <- optimization(par = c(x=0, y=10), 
		    fn = fn, methods=c("SANN", "Nelder"), 
		    control=list(maxit=20))
opt <- run.optimization(opt)
opt <- run.optimization(opt)
run.optimization(opt)
```

Here's the same example, with a transform that fixes $y$ at the value 10.

```{r}
fixparms <- function(parms) {
  fn0 <- NULL
  gr0 <- NULL
  unfixed <- is.na(parms)
  setfn <- function(fn, gr = NULL) {
    fn0 <<- fn
    gr0 <<- gr
  }
  forward <- function(par) {
    par[unfixed]
  }
  inverse <- function(par1) {
    result <- parms
    result[unfixed] <- par1
    result
  }
  fn1 <- function(par1, ...) fn0(inverse(par1), ...)
  gr1 <- function(par1, ...) gr0(inverse(par1), ...)[unfixed]
  list(setfn = setfn, forward = forward, inverse = inverse, fn1 = fn1, gr1 = gr1)
}

opt <- optimization(par = c(x = -2, y = 10), 
		    fn = fn, methods=c("SANN", "Brent", "BFGS"), 
		    lower = list(Brent = -5), 
		    upper = list(Brent = 100), 
		    transform = fixparms(c(NA, 10)),
		    control=list(maxit=20))
run.optimization(opt)
```

# What else?

* It should be possible to compose transformations
* We should have more examples of transformations
* More optimization methods should be supported