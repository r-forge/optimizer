---
title: "Animating geometric optimization: small polygons"
author: "John C. Nash, Greg Snow"
date: "`r Sys.Date()`"
output: pdf_document
## output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using and extending the optimr package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Abstract

**Roptanimation** is an experimental R package to display the progress of 
geometric animations. A classic example is the **largest small polygon** where
we aim to maximize the area of the polygon subject to the constraint that no
two vertices are separated by more than one unit of distance. This article discusses 
the problem and how the animation is created, but only shows snapshots of the 
animation.


## TODOS

  - make sure animation is running
  - comment and test the animation code
  - try nloptr
  - try ?? other optimizers
  - polyobju -- put in log barrier for the radial parameters so unconstrained
    minimizers can be used
  - try shiny for running the animation

## Background

The **The Largest Small Hexagon** is the title of a paper by
Ron Graham (J. Combinatorial Theory (A), vol. 18, pp. 165-170, 1975). This did
not introduce this problem, but served to bring it to wider attention. One of
the authors (JCN) used this problem to illustrate constrained optimization using
the tools in J.C. Nash and M. Walker-Smith (1987, Nonlinear parameter estimation:
an integrated system in BASIC, now available online at 
https://archive.org/details/ost-engineering-jnmws2004).

To provide a visual presentation of the optimization, Nash coded a display for the
IBM PC family of MS DOS computers running GWBASIC. In May 2016, the discovery that
files for this example would still execute more or less satisfactorily raised the
possibility of bringing them up to date. R was a logical choice for such an 
implementation, given that the authors and many others work with this software system. 

## Parametrization of the polygon

For a polygon with \texttt{nv} vertices, we have \texttt{2*nv} cartesian (i.e., x, y)
coordinates. However, use of cartesian coordinates as parameters for this problem 
leads to a very complicated specification, since 3 parameters can be fixed right
away. That is, we can fix one vertex at the \texttt{(0, 0)} or origin of our [2D] space.
Moreover, we can put the second vertex at \texttt{(b[1], 0)} where \texttt{b} is a vector of
\texttt{(2*nv - 3)} parameters. Changing to a representation that uses a radius from the
origin for vertex \texttt{L} equal to \texttt{b[L-1]}, we could use the angle of this vertex from the
positive \texttt{x} axis as a parameter. Call this angle \texttt{alpha[L]}. Clearly \texttt{alpha[1]} for 
vertex 2 is 0, so the 2nd vertex is still at \texttt{(b[1], 0)}. 

We could put the alpha angles in the parameter vector as b[L+lshift] where 
lshift = nv - 3. Thus the first non-zero angle is for vertex 3 and is parameter
3 + nv - 3 = nv. Check: there are (nv - 1) radius parameters, so the first angle
parameter is in position nv. There may be good implementations based on having
parameters b[nv] ... b[2*nv-3] equal to the angles for points 2...nv. However, 
that then requires the angles to be monotonically increasing. By specifying that
b[L+lshift] = alpha[L-1] - alpha[L-2] for L=3 ... nv, we automatically get the
angles alpha monotonic by imposing a lower bound of 0 on the parameters b. 

Note that the radii cannot be negative (in fact, zero is a bad idea too), so a lower
bound of 0 can be applied to all the parameters b. An upper bound of 1 clearly applies to
the first (nv - 1) parameters. The other (nv - 2) parameters are angles in radians. If
we are to have the polygon in the positive y half-space in cartesian coordinates, 
then pi is an obvious (and likely conservative) bound on these angles. In fact,
pi is a bound on their sum.

We make no assertion that this is the only or best parametrization of this problem, and
welcome suggestions for other ways to prepare the optimization.

## Problem setup

The above parametrization is implemented in the function \texttt{polysetup(nv, defsize)},
where \texttt{defsize} is the default "size" of a regular polygon for which initial parameters
are established. 

```{r cache=FALSE, echo=FALSE}
library(knitr) # This is critical -- or you don't get read_chunk()
read_chunk('/home/john/rsvnall/optimizer/pkg/Roptanimation/R/smallpoly2.R')
```


```{r polysetup}
```

The parameters of a regular hexagon of size 1 can be created as follows.

```{r}
# A regular hexagon of size 1
reghex1 <- polysetup(6, defsize=1)
cat("Parameters of the regular hexagon of unit size\n")
print(reghex1$par0)
```

## The polygon area

The parameterization of the problem allows the area to be computed as the sum of the areas of
the triangles made up from vertex \texttt{1} with vertex \texttt{L} and \texttt{(L+1)}
where \texttt{L} runs from \texttt{2} to \texttt{(nv-1)}.

```{r polyarea}
```

For reference, let us compute the area of this hexagon.

```{r}
reg1area <- polyarea(reghex1$par)
cat("Reference area of regular hexagon of unit size=",reg1area,"\n")
```

This is in accord with R.L. Graham's paper (JOURNAL OF COMBINATORIAL THEORY (A) 18, 165 - 470 (1975) ).


## Conversion of radial to cartesian coordinates

For drawing the current polygon, we need cartesian coordinates rather than the specially 
organized radial coordinates defined by the optimization parameters. The R function
\texttt{polypar2XY} carries out this computation and puts the \texttt{x, y} coordinates
in a two-vector list \texttt{XY}. \texttt{XY\$x} gives the \texttt{x} coordinates and 
\texttt{XY\$y} gives the \texttt{y} coordinates. To simplify the plotting of the polygon
the first and last values of each list are both 0 so that a graph with joining lines 
automatically gives the closed figure polygon.

```{r polypar2XY}
```

## Distance between polygon vertices

To verify constraints and to construct penalty or barrier functions for the optimization
process for this problem, we also need vertex to vertex distances. These are computed by 
the function \texttt{polydistXY}. This function uses the cartesian coordinates for the 
current polygon that result from running the function \texttt{polypar2XY}

```{r polydistXY}
```

## Vertex distances from radial parameters

We could compute these vertex distances from the radial parameters of the polygon.
The following function calls the conversion from radial to cartesian coordinates,
then computes the distances.

```{r polypar2distXY}
```

Alternatively, and perhaps more efficiently or at least elegantly, we can do a
one-step calculation. However, the following function ONLY computes the non-radial
inter-vertex differences. The first $nv - 1$ parameters where $nv$ is the number of 
vertices give the other distances. Moreover, the positions of these distances in 
the output of polypar2distXY are not obvious at first glance.

```{r polypardist2}

## Testing functions.

Note that we tested our functions to create the original polygon and compute it's area. 
This is a step that we recommend. In fact, one of us (JN) refuses to look at user queries
about his optimization routines unless there is evidence that objective functions and gradients
have been checked. It is an important part of the solution of EVERY optimization problem
that users verify that they are solving the intended problem. Moreover, even in our own work,
the simple checks often reveal silly but critical errors.

An example of a test script follows.

```{r polyex0, fig.width=5, fig.height=5}
```

## Setup of the optimization

The constrained optimization to maximize the area actually minimizes the negative area.
However, we need to account for the constraints. Clearly since the radial parameters
start at one vertex of the polygon, they are bounded above by 1. And naturally, we 
cannot have a polygon with negative lengths, so 0 is an obvious lower bound, though
realistically, some modest positive value would likely be workable. This accounts for
constraints on distance from the first, or base, vertex. For the other distances, we 
will apply a penalty function which will be added to the negative area. We can also
put 0 as a lower bound on the angular parameters, and a reasonable upper bound as well.
pi serves as a conservative bound for these parameters.

## Quadratic penalty function

Our first try (which we will state in advance does not work well) is to add a multiple
of the sum of the distance violations. These are the pairwise squared distances for those
inter-vertex distances that are not given by the radial parameters. We assume the simple
bounds are in force for the radial and angular parameters. This results in the following
objective function.

```{r polyobj1}
```

Setting the penalty factor ($penfactor$) at 100, we use M. J. Powell's bobyqa minimizer
to try to find the solution. 

```{r polyex1}
```
The objective is the negative area PLUS the penalty, so (-1) times this value is a lower 
bound on the area. But we see that it is smaller than the reference value (approximately
0.64952) of the unit regular hexagon. We also display the computed area directly, and it
shows that the constraint penalty is not appreciably contributing to the objective.
We clearly have more work to do.

## Making objective very large on constraint violation

An old "trick" in optimization is to use a non-gradient direct search method that 
assigns the objective function its correct value when the parameters are feasible 
and a very large value when they are violated. We supply the value of $bignum$ 
to the objective function via the call.

```{r polyobjbig}
```

To test several optimizers at once, we use the \texttt{opm()} function of the
R-forge package \texttt{optimz}. 

```{r polyexbig}
```

The two Nelder-Mead inspired codes are the best of a bad lot here, though neither has
got really close to the solution for the small hexagon problem. Note how different the
solutions appear. Let us draw them.

```{r fig.height=6, fig.width=6}
NMpar <- unlist(solb["Nelder-Mead",1:9])
nmkbpar <- unlist(solb["nmkb",1:9])
print(NMpar)
cat("Nelder-Mead area=", polyarea(NMpar))
print(nmkbpar)
cat("nmkb area=", polyarea(nmkbpar))
NMXY <- polypar2XY(NMpar)
nmkbXY <- polypar2XY(nmkbpar)
plot(NMXY$x, NMXY$y, col="red", type="l")
points(nmkbXY$x, nmkbXY$y, col="blue", type="l")
title(main="Hexagons from NM (red) and nmkb (blue)")

```
Drawing these polygons so we can visually compare them involves transformations that
must align the polygons so one edge is on the x axis. But which edge to choose as the
first. Then we must note that a vertical reflection of the polygon about the mid-point
of the chosen edge will result in an equivalent solution. These options remind us that
the optimization problem has multiple solutions, all with equal optimal area, which
is part of the difficulty of the largest small polygon problem.

## Logarithmic barrier constraint

A different kind of penalty is provided by the logarithmic barrier. This aims to keep
the parameters feasible by adding a steeply increasing function to the negative area as 
the constraint is approached. Let us first define the **slack** in a distance constraint
as $slack = (1 - squared.distance)$. We could use the distance itself, but might as well 
avoid the extra computation. As each slack goes to zero, then $- log(slack)$ goes to 
infinity. We can scale this, as in the quadratic penalty, with $penfactor$, but the
actual numerical value will be much smaller now because $- log()$ increases much more
quickly than the quadratic.

There is an annoying computational practicality that some optimization methods may take
steps in the parameter vector that push some distances into infeasible territory. This
will cause exceptions to be generated when the logarithm of a negative "slack" is 
attempted. To avoid this, we will simply make the objective function very large at
any time when there is a violation. However, this does cause grief for the evaluation
of numerical approximations to gradients, so we may want to revise this policy later
and seek more elegant (but likely more complicated) techniques to deal with this 
possibility. The large number for now will be $ bignum = 1e20 $.

Since the logarithmic barrier does not let the parameters end actually ON then bound,
we may wish to move the constraint an epsilon beyond 1 by redefining the slack as

$slack = (1 + epsilon - squared.distance)$

But what should $epsilon$ be? We may revisit this later, but for the moment set the 
value at 0, and the resulting code is as follows.

```{r polyobj}
```

With Powell's bobyqa, we attempt to minimize this objective from the same start as
before. We set the penalty factor quite small, in fact 0.01, as the barrier is non-zero within
the feasible region.

```{r polyex2}
```

This is not too bad. Possibly another method could do better. We can adjust the objective 
so the radial parameters are constrained using a logarithmic barrier, then use an unconstrained 
optimization method.

```{r polyobju}
```
        
```{r}
library(dfoptim)
sol2n <- nmk(x0, polyobju, penfactor=1e-3)
print(sol2n)
cat("Area found=",polyarea(sol2n$par),"\n")
```
