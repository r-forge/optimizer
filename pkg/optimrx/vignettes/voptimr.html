<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="John C. Nash (nashjc at uottawa.ca)" />

<meta name="date" content="2016-06-29" />

<title>Using and extending the optimr package</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Using and extending the optimr package</h1>
<h4 class="author"><em>John C. Nash (nashjc <em>at</em> uottawa.ca)</em></h4>
<h4 class="date"><em>2016-06-29</em></h4>



<div id="section" class="section level2">
<h2></h2>
</div>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p><strong>optimr</strong> is a package intended to provide improved and extended function minimization tools for R. Such facilities are commonly referred to as “optimization”, but the original <code>optim()</code> function and its replacement in this package, which has the same name as the package, namely <code>optimr()</code>, only allow for the minimization or maximization of nonlinear functions of multiple parameters subject to at most bounds constraints. Many methods offer extra facilities, but apart from <strong>masks</strong> (fixed parameters) for the <code>Rcgmin</code> and <code>Rvmmin</code>, such features are likely inaccessible via this package.</p>
<p>In general, we wish to find the vector of parameters <code>bestpar</code> that minimize an objective function specified by an R function <code>fn(par, ... )</code> where <code>par</code> is the general vector of parameters, initially provided as the vector <code>par0</code>, and the dot arguments are additional information needed to compute the function. Function minimization methods may require information on the gradient or Hessian of the function, which we will assume to be furnished, if required, by functions <code>gr(par, ...)</code> and <code>hess(par, ....)</code>. Bounds or box constraints, if they are to be imposed, are given in the vectors <code>lower</code> and <code>upper</code>.</p>
<p>As far as I am aware, all the optimizers included in the <code>optimr</code> package are <strong>local</strong> minimizers. That is, they attempt to find a local minimum of the objective function. Global optimization is a much bigger problem. Even finding a local minimum can often be difficult, and to that end, the package includes a function <code>kktchk()</code> to test the Kuhn-Karush-Tucker conditions. These essentially require that a local minumum has a zero gradient and all nearby points on the function surface have a greater function value. There are many details that are ignored in this very brief explanation.</p>
<p>It is intended that <code>optimr</code> can and should be extended with new optimizers and perhaps with extra functionality. Moreover, such extensions should be possible for an R user reasonably proficient in programming R scripts. These changes would, of course, be made by downloading the source of the package and modifying the R code to make a new, but only locally available, package. The author does, on the other hand, welcome suggestions for inclusion in the distributed package, especially if these have been well-documented and tested. Over 95% of the effort in building <code>optimr</code> has been to try to ensure that errors and conflicts are purged, and that the code is resistant to mistakes in user inputs.</p>
</div>
<div id="how-the-optimr-function-generally-works" class="section level2">
<h2>How the optimr() function (generally) works</h2>
<p><code>optimr()</code> is an aggregation of wrappers for a number of individual function minimization (“optimization”) tools available for R. The individual wrappers are selected by a sequence of <code>if()</code> statements using the argument <code>method</code> in the call to <code>optimr()</code>.</p>
<p>To add a new optimizer, we need in general terms to carry out the following:</p>
<ul>
<li>Ensure the new function is available, that is, the package containing it is installed, and the functions <code>import</code>ed into <code>optimr</code>;</li>
<li>Add an appropriate <code>if()</code> statement to select the new “method”;</li>
<li>Translate the <code>control</code> list elements of <code>optimr()</code> into the corresponding control arguments (possibly not in a list of that name but in one or more other structures, or even arguments or environment variables) for the new “method”;</li>
<li>If necessary, redefine the R function or functions to compute the value of the function, gradient and possibly Hessian of the objective function so that the output is suited to the method at hand.</li>
<li>When derivative information is required by a method, we may also need to incorporate the possibility of numerical approximations to the derivative information.</li>
<li>Add code to check for situations where the new method cannot be applied, and in such cases return a result with appropriate diagnostic information so that the user can either adjust the inputs or else choose a different method.</li>
<li>Provide, if required, appropriate links to modified function and gradient routines that allow the parameter scaling <code>control$parscale</code> to be applied if this funtionality is not present in the methods. To my knowledge, only the base <code>optim()</code> function methods do not need such special scaling provisions.</li>
<li>As needed, back-transform scaled parameters and other output of the different optimization methods.</li>
</ul>
<div id="bounds" class="section level3">
<h3>Bounds</h3>
<p>A number of methods support the inclusion of box (or bounds) constraints. This includes the function <code>nmkb()</code> from package <code>dfoptim</code>. Unfortunately, this function uses the transfinite transformation of the objective function to impose the bounds (ref??), which causes and error if any of the initial parameters are on one of the bounds.</p>
<p>There are several improvements in the <code>optimr</code> package that would be especially nice to see, but I do not have any good ideas yet how to implement them all. Among these unresolved improvements are:</p>
<ul>
<li>to use the transfinite approach to permit bounds to be supplied for all the unconstrained optimization methods;</li>
<li>to automatically adjust the bounds or the parameters very slightly to allow initial parameter sets to be provided with the initial parameters on a bound. I think it would be important to issue a warning in such cases.</li>
<li>to flag or otherwise indicate to the user which approach has been used, and also to allow control of the approach. For example, the transfinite approach could be used with some of the methods that allow bounds. Note that these possibilities increase the complexity of the code and may be prone to bugs.</li>
</ul>
</div>
<div id="masks-fixed-parameters" class="section level3">
<h3>Masks (fixed parameters)</h3>
<p>The methods <code>Rcgmin</code> and <code>Rvmmin</code> (and possibly others, but not obviously accessible via this package) also permit fixed (masked) parameters. This is useful when we want to establish an objective function where one or more of the parameters is supplied a value in most situations, or for which we want to fix a value while we optimize the other parameters. At another time, we may want to allow such parameters to be part of the optimization process.</p>
<p>In principle, we could fix parameters in methods that allow bounds constraints by simply setting the lower and upper bounds equal for the parameters to be masked. As a computational approach, this is generally a very bad idea, but in the present <code>optimr()</code> this is permitted for methods <code>Rcgmin</code> and <code>Rvmmin</code> but should give an error for other bounds-capable methods. In the case of the two methods mentioned, the bounds signal that masks are active, and the parameters in question are more or less excluded from the computations except for their role in evaluating function and gradient values.</p>
</div>
</div>
<div id="issues-in-adding-a-new-method" class="section level2">
<h2>Issues in adding a new method</h2>
<div id="adjusting-the-objective-function-for-different-methods" class="section level3">
<h3>Adjusting the objective function for different methods</h3>
<p>The method <code>nlm()</code> provides a good example of a situation where the default <code>fn()</code> and <code>gr()</code> are inappropriate to the method to be added to <code>optimr()</code>. We need a function that returns not only the function value at the parameters but also the gradient and possibly the hessian. Don’t forget the dot arguments which are the exogenous data for the function!</p>
<p>??? do we want spar?</p>
<pre><code>  nlmfn &lt;- function(par, ...){
     f &lt;- fn(par, ...)
     g &lt;- gr(par, ...)
     attr(f,&quot;gradient&quot;) &lt;- g
     attr(f,&quot;hessian&quot;) &lt;- NULL # ?? maybe change later
     f
  }</code></pre>
<p>In the present <code>optimr()</code>, the definition of <code>nlmfn</code> is put near the top of <code>optimr()</code> and it is always loaded. It is the author’s understanding that such functions will always be loaded/interpreted no matter where they are in the code of a function. For ease of finding the code, and as a former Pascal programmer, I have put it near the top, as the structure can be then shared across several similar optimizers. There are other methods that compute the objective function and gradient at the same set of parameters. Though <code>nlm()</code> can make use of Hessian information, we have chosen here to omit the computation of the Hessian.</p>
</div>
<div id="parameter-scaling" class="section level3">
<h3>Parameter scaling</h3>
<p>Parameter scaling is a feature of the original <code>optim()</code> but generally not provided in many other optimizers. It has been included (at times with some difficulty) in the <code>optimr()</code> function. The construct is to provide a vector of scaling factors via the <code>control</code> list in the element <code>parscale</code>. In the tests of the package, and as an example of the use and utility of scaling, we use the Hobbs weed infestation problem (./tests/hobbs15b.R). This is a nonlinear least squares problem to estimate a three-parameter logistic function using data for 12 periods. This problem has a solution near the parameters c(196, 49, 0.3). In the test, we try starting from c(300, 50, 0.3) and from the much less informed c(1,1,1). In both cases, the scaling lets us find the solution more reliably. The timings and number of function and gradient evaluations are, however, not necessarily improved for the methods that “work” (though these measures are all somewhat unreliable because they may be defined or evaluated differently in different methods – we use the information returned by the packages rather than insert counters into functions). However, what values of these measures should we apply for a failed method?</p>
</div>
<div id="function-scaling" class="section level3">
<h3>Function scaling</h3>
<p><code>optim()</code> uses <code>control$fnscale</code> to “scale” the value of the function or gradient computed by <code>fn</code> or <code>gr</code> respectively. In practice, the only use for this scaling is to convert a maximization to a minimization. Most of the methods applied are function <strong>minimization</strong> tools, so that if we want to maximize a function, we minimize its negative. Some methods actually have the possibility of maximization, and include a <code>maximize</code> control. In these cases having both <code>fnscale</code> and <code>maximize</code> could create a conflict. We check for this in <code>optimr()</code> and try to ensure both controls are set consistently.</p>
</div>
<div id="modified-unused-or-unwanted-controls" class="section level3">
<h3>Modified, unused or unwanted controls</h3>
<p>Because different methods use different control parameters, and may even put them into arguments rather than the <code>control</code> list, A lot of the code in <code>optimr()</code> is purely for translating or transforming the names and values to achieve the desired result. This is sometimes not possible precisely. A method which uses <code>control$trace = TRUE</code> (a logical element) has only “on” or “off” for controlling output. Other methods use an integer for this <code>trace</code> object, or call it something else that is an integer, in which case there are more levels of output possible.</p>
<p>I have found that it is important to remove (i.e., set NULL) controls that are not used for a method. Moreover, since R can leave objects in the workspace, I find it important to set any unused or unwanted control to NULL both before and after calling a method.</p>
<p>Thus, if <code>print.level</code> is the desired control, and it more or less matches the <code>optimr()</code> <code>control$trace</code>, we need to set</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">   print.level &lt;-<span class="st"> </span>control$trace
   control$trace &lt;-<span class="st"> </span><span class="ot">NULL</span></code></pre></div>
</div>
<div id="running-multiple-methods" class="section level3">
<h3>Running multiple methods</h3>
<p>It is often convenient to be able to run multimple optimization methods on the same function and gradient. To this end, the function <code>opm()</code> is supplied. The output of this by default includes the KKT tests and other informatin in a data frame, and there are convenience methods <code>summary()</code> and <code>coef()</code> to allow for display or extraction of results.</p>
</div>
</div>
<div id="derivatives" class="section level2">
<h2>Derivatives</h2>
<p>Derivative information is used by many optimization methods. In particular, the <strong>gradient</strong> is the vector of first derivatives of the objective function and the <strong>hessian</strong> is its second derivative. It is generally non-trivial to write a function for a gradient, and generally a lot of work to write the hessian function.</p>
<p>While there are derivative-free methods, we may also choose to employ numerical approximations for derivatives. Some of the optimizers called by <code>optimr</code> automatically provide a numerical approximation if the gradient function (typically called <code>gr</code>) is not provided or set NULL. However, I believe this is open to abuse and also a source of confusion, since we may not be informed in the results what approximation has been used.</p>
<p>For example, the package <code>numDeriv</code> has functions for the gradient and hessian, and offers three methods, namely a Richardson extrapolation (the default), a complex step method, and a “simple” method. The last is either a forward of backward approximation controlled by an extra argument <code>side</code> to the <code>grad()</code> function. The complex step method, which offers essentially analytic precision from a very efficient computation, is unfortunately only applicable if the objective function has specific properties. That is, according to the documentation:</p>
<pre><code> This method requires that the function be able to
 handle complex valued arguments and return the appropriate complex
 valued result, even though the user may only be interested in the
 real-valued derivatives.  It also requires that the complex
 function be analytic.</code></pre>
<p>The default method of <code>numDeriv</code> generally require multiple evaluations of the objective function to approximate a derivative. The simpler choices, namely, the forward, backward and central approximations, require respectively 1, 1, and 2 function evaluations.</p>
<p>To keep the code straightforward, I decided that if an approximate gradient is to be used by <code>optimr</code> (or by extension the multiple method routine <code>opm()</code>), then the user should specify the name of the approximation routine as a character string in quotations marks. The package supplies four gradient approximation functions for this purpose, namely “grfwd” and “grback” for the forward and backward simple approximations, “grcentral” for the central approximation, and “grnd” for the default Richardson method via <code>numDeriv</code>. It should be fairly straightforward for a user to copy the structure of any of these routines and call their own gradient, but at the time of writing this (2016-6-29) I have not tried to do so. An example using the complex step derivative would be useful to include in this vignette.</p>
<p>?? comparison of speed and accuracy??</p>
</div>
<div id="functions-besides-optimr-in-the-package" class="section level2">
<h2>Functions besides <code>optimr()</code> in the package</h2>
<div id="opm" class="section level3">
<h3>opm()</h3>
<p>As mentioned above, this routine allows a vector of methods to be applied to a given function and (optionally) gradient. The pseudo-method “ALL” (upper case) can be given on its own (not in a vector) to run all available methods. If bounds are given, “ALL” restricts the set to the methods that can deal with bounds.</p>
</div>
<div id="kktchk" class="section level3">
<h3>kktchk()</h3>
<p>This routine, which can be called independently for checking the results of other optimization tools, checks the KKT conditions for a given set of parameters that are thought to describe a local optimum.</p>
</div>
<div id="grfwd-grback-grcentral-and-grnd" class="section level3">
<h3>grfwd(), grback(), grcentral() and grnd()</h3>
<p>These have be discussed above under Derivatives.</p>
</div>
<div id="fnchk-grchk-and-hesschk" class="section level3">
<h3>fnchk(), grchk() and hesschk()</h3>
<p>These functions are provided to allow for detection of user errors in supplied function, gradient or hessian functions. Though we do not yet use hessians in the optimizers called, it is hoped that eventually they can be incorporated.</p>
<p><code>fnchk()</code> is mainly a tool to ensure that the supplied function returns a finite scalar value when evaluated at the supplied parameters.</p>
<p>The other routines use numerical approximations (from <code>numDeriv</code>) to check the derivative functions supplied by the user.</p>
</div>
<div id="bmchk" class="section level3">
<h3>bmchk()</h3>
<p>This routine is intended to trap errors in setting up bounds and masks for function minimization problems. In particular, we are looking for situations where parameters are outside the bounds or where bounds are impossible to satisfy (e.g., lower &gt; upper). This routine creates an indicator vector called bdmsk whose values are 1 for free parameters, 0 for masked (fixed) parameters, -3 for parameters at their lower bound and -1 for those at their upper bound. (The particular values are related to a coding trick for BASIC in the early 1980s.)</p>
</div>
<div id="scalechk" class="section level3">
<h3>scalechk()</h3>
<p>This routine is an attempt to check if the parameters and bounds are roughly similar in their scale. Unequal scaling can result in poor outcomes when trying to optimize functions using derivative free methods that try to search the paramter space. Note that the attempt to include parameter scaling for all methods is intended to provide a work-around for such bad scaling.</p>
</div>
<div id="optchk" class="section level3">
<h3>optchk()</h3>
<p>This routine is an attempt to consolidate the function, gradient and scale checks.</p>
</div>
<div id="ctrldefault" class="section level3">
<h3>ctrldefault()</h3>
<p>This routine provides default values for the <code>control</code> vector that is applicable to all the methods for a given size of problem. The single argument to this function is the number of parameters, which is used to compute values for termination tolerances and limits on function and gradient evaluations. However, while I believe the values computed are “reasonable” in general, for specific problems they may be wildly inappropriate.</p>
</div>
</div>
<div id="testing-the-package" class="section level2">
<h2>Testing the package</h2>
<ul>
<li>individual method tests</li>
<li>problem tests</li>
</ul>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
