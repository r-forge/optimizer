---
title: "Animating geometric optimization: small polygons"
author: "John C. Nash, A. N. Other"
date: "`r Sys.Date()`"
output: pdf_document
## output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using and extending the optimr package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

**Roptanimation** is an experimental R package to display the progress of 
geometric animations. A classic example is the **largest small polygon** where
we aim to maximize the area of the polygon subject to the constraint that no
two vertices are separated by more than one unit of distance.

## Background

The **The Largest Small Hexagon** is the title of a paper by
Ron Graham (J. Combinatorial Theory (A), vol. 18, pp. 165-170, 1975). This did
not introduce this problem, but served to bring it to wider attention. One of
the authors (JCN) used this problem to illustrate constrained optimization using
the tools in J.C. Nash and M. Walker-Smith (1987, Nonlinear parameter estimation:
an integrated system in BASIC, now available online at 
https://archive.org/details/ost-engineering-jnmws2004).

To provide a visual presentation of the optimization, Nash coded a display for the
IBM PC family of MS DOS computers running GWBASIC. In May 2016, the discovery that
files for this example would still execute more or less satisfactorily raised the
possibility of bringing them up to date. R was a logical choice for such an 
implementation, given that the authors all work with this software system. 

## Parametrization of the polygon

For a polygon with \texttt{nv} vertices, we have \texttt{2*nv} cartesian (i.e., x, y)
coordinates. However, use of cartesian coordinates as parameters for this problem 
leads to a very complicated specification, since 3 parameters can be fixed right
away. That is, we can fix one vertex at the \texttt{(0, 0)} or origin of our [2D] space.
Moreover, we can put the second vertex at \texttt{(b[1], 0)} where \texttt{b} is a vector of
\texttt{(2*nv - 3)} parameters. Changing to a representation that uses a radius from the
origin for vertex \texttt{L} equal to \texttt{b[L-1]}, we could use the angle of this vertex from the
positive \texttt{x} axis as a parameter. Call this angle \texttt{alpha[L]}. Clearly \texttt{alpha[1]} for 
vertex 2 is 0, so the 2nd vertex is still at \texttt{(b[1], 0)}. 

We could put the alpha angles in the parameter vector as b[L+lshift] where 
lshift = nv - 3. Thus the first non-zero angle is for vertex 3 and is parameter
3 + nv - 3 = nv. Check: there are (nv - 1) radius parameters, so the first angle
parameter is in position nv. There may be good implementations based on having
parameters b[nv] ... b[2*nv-3] equal to the angles for points 2...nv. However, 
that then requires the angles to be monotonically increasing. By specifying that
b[L+lshift] = alpha[L-1] - alpha[L-2] for L=3 ... nv, we automatically get the
angles alpha monotonic by imposing a lower bound of 0 on the parameters b. 

Note that the radii cannot be negative (in fact, zero is a bad idea too), so a lower
bound of 0 can be applied to all the parameters b. An upper bound of 1 clearly applies to
the first (nv - 1) parameters. The other (nv - 2) parameters are angles in radians. If
we are to have the polygon in the positive y half-space in cartesian coordinates, 
then pi is an obvious (and likely conservative) bound on these angles. In fact,
pi is a bound on their sum.

## Problem setup

The above parametrization is implemented in the function \texttt{polysetup(nv, defsize, qpen)},
where \texttt{defsize} is the default "size" of a regular polygon for which initial parameters
are established. \texttt{qpen} is a multiplicative factor for a penalty function that may be
used to impose the distance constraints. However, the form of this penalty is not
yet given. 

```{r cache=FALSE, echo=FALSE}
library(knitr) # This is critical -- or you don't get read_chunk()
read_chunk('../R/smallpoly.R')
```


```{r polysetup}
```

The parameters of a regular hexagon of size 1 can be created as follows.

```{r}
# A regular hexagon of size 1
reghex1 <- polysetup(6, defsize=1)
cat("Parameters of the regular hexagon of unit size\n")
print(reghex1$par0)
```

## The polygon area

The parameterization of the problem allows the area to be computed as the sum of the areas of
the triangles made up from vertex \texttt{1} with vertex \texttt{L} and \texttt{(L+1)}
where \texttt{L} runs from \texttt{2} to \texttt{(nv-1)}.

```{r polyarea}
```

For reference, let us compute the area of this hexagon.

```{r}
reg1area <- polyarea(6, reghex1$par)
cat("Reference area of regular hexagon of unit size=",reg1area,"\n")
```

This is in accord with R.L. Graham's paper (JOURNAL OF COMBINATORIAL THEORY (A) 18, 165 - 470 (1975) ).

## Conversion of radial to cartesian coordinates

For drawing the current polygon, we need cartesian coordinates rather than the specially 
organized radial coordinates defined by the optimization parameters. The R function
\texttt{polypar2XY} carries out this computation and puts the \texttt{x, y} coordinates
in a two-vector list \texttt{XY}. \texttt{XY\$x} gives the \texttt{x} coordinates and 
\texttt{XY\$y} gives the \texttt{y} coordinates. To simplify the plotting of the polygon
the first and last values of each list are both 0 so that a graph with joining lines 
automatically gives the closed figure polygon.

```{r polypar2XY}
```

## Distance between polygon vertices

To verify constraints and to construct penalty or barrier functions for the optimization
process for this problem, we also need vertex to vertex distances. These are computed by 
the function \texttt{polydistXY}. This function uses the cartesian coordinates for the 
current polygon that result from running the function \texttt{polypar2XY}

```{r polydistXY}
```

## Testing the functions presented so far.

A very simple script calling the above functions allows us to verify that they are
working as expected. Note that for this script to work properly, we need to ensure
that the graph is drawn on a square grid. 

```{r polyex0, fig.width=5, fig.height=5}
```


## Setup of the optimization

The constrained optimization to maximize the area actually minimizes the negative area.
However, we need to account for the constraints. Clearly since the radial parameters
start at one vertex of the polygon, they are bounded above by 1. And naturally, we 
cannot have a polygon with negative lengths, so 0 is an obvious lower bound, though
realistically, some modest positive value would likely be workable. This accounts for
constraints on distance from the first, or base, vertex. For the other distances, we 
will apply a penalty function which will be added to the negative area. We can also
put 0 as a lower bound on the angular parameters, and a reasonable upper bound as well.
pi serves as a conservative bound for these parameters.

## Quadratic penalty function

Our first try (which we will state in advance does not work well) is to add a multiple
of the sum of the distance violations. These are the pairwise squared distances for those
inter-vertex distances that are not given by the radial parameters. We assume the simple
bounds are in force for the radial and angular parameters. This results in the following
objective function.

```{r polyobj1}
```

Setting the penalty factor ($penfactor$) at 100, we use M. J. Powell's bobyqa minimizer
to try to find the solution. 

```{r polyex1}
```
The objective is the negative area PLUS the penalty, so (-1) times this value is a lower 
bound on the area. But we see that it is smaller than the reference value (approximately
0.64952) of the unit regular hexagon. We have more work to do.

## Logarithmic barrier constraint

A different kind of penalty is provided by the logarithmic barrier. This aims to keep
the parameters feasible by adding a steeply increasing function to the negative area as 
the constraint is approached. Let us first define the **slack** in a distance constraint
as $slack = (1 - squared.distance)$. We could use the distance itself, but might as well 
avoid the extra computation. As each slack goes to zero, then $- log(slack)$ goes to 
infinity. We can scale this, as in the quadratic penalty, with $penfactor$.

There is an annoying computational practicality that some optimization methods may take
steps in the parameter vector that push some distances into infeasible territory. This
will cause exceptions to be generated when the logarithm of a negative "slack" is 
attempted. To avoid this, we will simply make the objective function very large at
any time when there is a violation. However, this does cause grief for the evaluation
of numerical approximations to gradients, so we may want to revise this policy later
and seek more elegant (but likely more complicated) techniques to deal with this 
possibility. The large number for now will be $ bignum = 1e20 $.

Since the logarithmic barrier does not let the parameters end actually ON then bound,
we may wish to move the constraint an epsilon beyond 1 by redefining the slack as

$slack = (1 + epsilon - squared.distance)$

But what should $epsilon$ be? We may revisit this later, but for the moment set the 
value at 0, and the resulting code is as follows.

```{r polyobj2 }
```

With Powell's bobyqa, we attempt to minimize this objective from the same start as
before. We set the penalty factor quite small, in fact 0.01, as the barrier is non-zero within
the feasible region.

```{r polyex2}
```


        
